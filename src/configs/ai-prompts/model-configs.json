{
  "openai_gpt4": {
    "max_tokens": 4000,
    "temperature": 0.7,
    "response_format": "json",
    "system_message_style": "professional",
    "context_window": 32000,
    "supports_json_mode": true
  },
  "openai_gpt35": {
    "max_tokens": 3000,
    "temperature": 0.7,
    "response_format": "json",
    "system_message_style": "concise",
    "context_window": 16000,
    "supports_json_mode": true
  },
  "claude_sonnet": {
    "max_tokens": 4000,
    "temperature": 0.7,
    "response_format": "json",
    "system_message_style": "structured",
    "context_window": 200000,
    "supports_json_mode": false
  },
  "claude_haiku": {
    "max_tokens": 3000,
    "temperature": 0.7,
    "response_format": "json",
    "system_message_style": "concise",
    "context_window": 200000,
    "supports_json_mode": false
  },
  "gemini_pro": {
    "max_tokens": 4000,
    "temperature": 0.7,
    "response_format": "json",
    "system_message_style": "conversational",
    "context_window": 32000,
    "supports_json_mode": true
  },
  "gemini_flash": {
    "max_tokens": 3000,
    "temperature": 0.7,
    "response_format": "json",
    "system_message_style": "efficient",
    "context_window": 32000,
    "supports_json_mode": true
  }
}